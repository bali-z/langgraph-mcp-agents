import streamlit as st
import asyncio
import nest_asyncio
import json
import os
import platform

if platform.system() == "Windows":
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

# nest_asyncio åº”ç”¨ï¼šå…è®¸åœ¨å·²è¿è¡Œçš„äº‹ä»¶å¾ªç¯ä¸­åµŒå¥—è°ƒç”¨
nest_asyncio.apply()

# å…¨å±€äº‹ä»¶å¾ªç¯çš„åˆ›å»ºä¸å¤ç”¨ï¼ˆåˆ›å»ºä¸€æ¬¡åæŒç»­ä½¿ç”¨ï¼‰
if "event_loop" not in st.session_state:
    loop = asyncio.new_event_loop()
    st.session_state.event_loop = loop
    asyncio.set_event_loop(loop)

from langgraph.prebuilt import create_react_agent
from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from dotenv import load_dotenv
from langchain_mcp_adapters.client import MultiServerMCPClient
from utils import astream_graph, random_uuid
from langchain_core.messages.ai import AIMessageChunk
from langchain_core.messages.tool import ToolMessage
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.runnables import RunnableConfig

# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆä» .env æ–‡ä»¶ä¸­è·å– API å¯†é’¥ç­‰è®¾ç½®ï¼‰
load_dotenv(override=True)

# è®¾ç½® config.json æ–‡ä»¶è·¯å¾„
CONFIG_FILE_PATH = "config.json"

# åŠ è½½ JSON é…ç½®æ–‡ä»¶çš„å‡½æ•°
def load_config_from_json():
    """
    ä» config.json æ–‡ä»¶åŠ è½½è®¾ç½®ã€‚
    å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨é»˜è®¤è®¾ç½®åˆ›å»ºæ–‡ä»¶ã€‚

    è¿”å›å€¼ï¼š
        dict: åŠ è½½çš„è®¾ç½®
    """
    default_config = {
        "get_current_time": {
            "command": "python",
            "args": ["./mcp_server_time.py"],
            "transport": "stdio"
        }
    }
    
    try:
        if os.path.exists(CONFIG_FILE_PATH):
            with open(CONFIG_FILE_PATH, "r", encoding="utf-8") as f:
                return json.load(f)
        else:
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™ç”¨é»˜è®¤è®¾ç½®åˆ›å»ºæ–‡ä»¶
            save_config_to_json(default_config)
            return default_config
    except Exception as e:
        st.error(f"é…ç½®æ–‡ä»¶åŠ è½½å‡ºé”™: {str(e)}")
        return default_config

# ä¿å­˜ JSON é…ç½®æ–‡ä»¶çš„å‡½æ•°
def save_config_to_json(config):
    """
    å°†è®¾ç½®ä¿å­˜åˆ° config.json æ–‡ä»¶ã€‚

    å‚æ•°ï¼š
        config (dict): è¦ä¿å­˜çš„è®¾ç½®
    
    è¿”å›å€¼ï¼š
        bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
    """
    try:
        with open(CONFIG_FILE_PATH, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        st.error(f"é…ç½®æ–‡ä»¶ä¿å­˜å‡ºé”™: {str(e)}")
        return False

# ç™»å½•ä¼šè¯å˜é‡åˆå§‹åŒ–
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

# æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•
use_login = os.environ.get("USE_LOGIN", "false").lower() == "true"

# æ ¹æ®ç™»å½•çŠ¶æ€æ›´æ”¹é¡µé¢è®¾ç½®
if use_login and not st.session_state.authenticated:
    # ç™»å½•é¡µé¢ä½¿ç”¨é»˜è®¤ï¼ˆçª„ï¼‰å¸ƒå±€
    st.set_page_config(page_title="Agent with MCP Tools", page_icon="ğŸ§ ")
else:
    # ä¸»åº”ç”¨ä½¿ç”¨å®½å¸ƒå±€
    st.set_page_config(page_title="Agent with MCP Tools", page_icon="ğŸ§ ", layout="wide")

# å¦‚æœå¯ç”¨äº†ç™»å½•åŠŸèƒ½ä¸”å°šæœªè®¤è¯ï¼Œåˆ™æ˜¾ç¤ºç™»å½•ç•Œé¢
if use_login and not st.session_state.authenticated:
    st.title("ğŸ” ç™»å½•")
    st.markdown("ç³»ç»Ÿä½¿ç”¨éœ€è¦ç™»å½•ã€‚")

    # ç™»å½•è¡¨å•å±…ä¸­æ˜¾ç¤º
    with st.form("login_form"):
        username = st.text_input("è´¦å·")
        password = st.text_input("å¯†ç ", type="password")
        submit_button = st.form_submit_button("ç™»å½•")

        if submit_button:
            expected_username = os.environ.get("USER_ID")
            expected_password = os.environ.get("USER_PASSWORD")

            if username == expected_username and password == expected_password:
                st.session_state.authenticated = True
                st.success("âœ… ç™»å½•æˆåŠŸï¼è¯·ç¨å€™â€¦â€¦")
                st.rerun()
            else:
                st.error("âŒ è´¦å·æˆ–å¯†ç ä¸æ­£ç¡®ã€‚")

    # ç™»å½•ç•Œé¢ä¸æ˜¾ç¤ºä¸»åº”ç”¨
    st.stop()

# åœ¨ä¾§è¾¹æ é¡¶éƒ¨æ·»åŠ ä½œè€…ä¿¡æ¯ï¼ˆä¼˜å…ˆäºå…¶ä»–ä¾§è¾¹æ å…ƒç´ ï¼‰
st.sidebar.markdown("### âœï¸ ä½œè€…ï¼š[Teddynote](https://youtube.com/c/teddynote) ğŸš€")
st.sidebar.markdown(
    "### ğŸ’» [Project Page](https://github.com/teddynote-lab/langgraph-mcp-agents)"
)

st.sidebar.divider()  # æ·»åŠ åˆ†å‰²çº¿

# é¡µé¢æ ‡é¢˜ä¸æè¿°
st.title("ğŸ’¬ MCP å·¥å…·æ™ºèƒ½ä½“")
st.markdown("âœ¨ å‘åŸºäº MCP å·¥å…·çš„ ReAct æ™ºèƒ½ä½“æé—®å§ã€‚")

SYSTEM_PROMPT = """<ROLE>
You are a smart agent with an ability to use tools. 
You will be given a question and you will use the tools to answer the question.
Pick the most relevant tool to answer the question. 
If you are failed to answer the question, try different tools to get context.
Your answer should be very polite and professional.
</ROLE>

----

<INSTRUCTIONS>
Step 1: Analyze the question
- Analyze user's question and final goal.
- If the user's question is consist of multiple sub-questions, split them into smaller sub-questions.

Step 2: Pick the most relevant tool
- Pick the most relevant tool to answer the question.
- If you are failed to answer the question, try different tools to get context.

Step 3: Answer the question
- Answer the question in the same language as the question.
- Your answer should be very polite and professional.

Step 4: Provide the source of the answer(if applicable)
- If you've used the tool, provide the source of the answer.
- Valid sources are either a website(URL) or a document(PDF, etc).

Guidelines:
- If you've used the tool, your answer should be based on the tool's output(tool's output is more important than your own knowledge).
- If you've used the tool, and the source is valid URL, provide the source(URL) of the answer.
- Skip providing the source if the source is not URL.
- Answer in the same language as the question.
- Answer should be concise and to the point.
- Avoid response your output with any other information than the answer and the source.  
</INSTRUCTIONS>

----

<OUTPUT_FORMAT>
(concise answer to the question)

**Source**(if applicable)
- (source1: valid URL)
- (source2: valid URL)
- ...
</OUTPUT_FORMAT>
"""

OUTPUT_TOKEN_INFO = {
    "claude-3-5-sonnet-latest": {"max_tokens": 8192},
    "claude-3-5-haiku-latest": {"max_tokens": 8192},
    "claude-3-7-sonnet-latest": {"max_tokens": 64000},
    "gpt-4o": {"max_tokens": 16000},
    "gpt-4o-mini": {"max_tokens": 16000},
}

# ä¼šè¯çŠ¶æ€åˆå§‹åŒ–
if "session_initialized" not in st.session_state:
    st.session_state.session_initialized = False  # ä¼šè¯åˆå§‹åŒ–çŠ¶æ€æ ‡å¿—
    st.session_state.agent = None  # å­˜å‚¨ ReAct ä»£ç†å¯¹è±¡
    st.session_state.history = []  # å­˜å‚¨å¯¹è¯è®°å½•çš„åˆ—è¡¨
    st.session_state.mcp_client = None  # å­˜å‚¨ MCP å®¢æˆ·ç«¯å¯¹è±¡
    st.session_state.timeout_seconds = 120  # å“åº”ç”Ÿæˆè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤120ç§’
    st.session_state.selected_model = "claude-3-7-sonnet-latest"  # é»˜è®¤æ¨¡å‹é€‰æ‹©
    st.session_state.recursion_limit = 100  # é€’å½’è°ƒç”¨é™åˆ¶ï¼Œé»˜è®¤100

if "thread_id" not in st.session_state:
    st.session_state.thread_id = random_uuid()


# --- å‡½æ•°å®šä¹‰éƒ¨åˆ† ---


async def cleanup_mcp_client():
    """
    å®‰å…¨å…³é—­ç°æœ‰çš„ MCP å®¢æˆ·ç«¯ã€‚

    å¦‚æœå­˜åœ¨æ—§å®¢æˆ·ç«¯ï¼Œåˆ™æ­£å¸¸é‡Šæ”¾èµ„æºã€‚
    """
    if "mcp_client" in st.session_state and st.session_state.mcp_client is not None:
        try:

            await st.session_state.mcp_client.__aexit__(None, None, None)
            st.session_state.mcp_client = None
        except Exception as e:
            import traceback

            # st.warning(f"MCP å®¢æˆ·ç«¯å…³é—­å‡ºé”™: {str(e)}")
            # st.warning(traceback.format_exc())


def print_message():
    """
    åœ¨ç•Œé¢ä¸Šè¾“å‡ºèŠå¤©è®°å½•ã€‚

    åŒºåˆ†ç”¨æˆ·å’ŒåŠ©æ‰‹çš„æ¶ˆæ¯ï¼Œå¹¶åœ¨åŠ©æ‰‹æ¶ˆæ¯å®¹å™¨ä¸­æ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯ã€‚
    """
    i = 0
    while i < len(st.session_state.history):
        message = st.session_state.history[i]

        if message["role"] == "user":
            st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").markdown(message["content"])
            i += 1
        elif message["role"] == "assistant":
            # åˆ›å»ºåŠ©æ‰‹æ¶ˆæ¯å®¹å™¨
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                # æ˜¾ç¤ºåŠ©æ‰‹æ¶ˆæ¯å†…å®¹
                st.markdown(message["content"])

                # æ£€æŸ¥ä¸‹ä¸€ä¸ªæ¶ˆæ¯æ˜¯å¦ä¸ºå·¥å…·è°ƒç”¨ä¿¡æ¯
                if (
                    i + 1 < len(st.session_state.history)
                    and st.session_state.history[i + 1]["role"] == "assistant_tool"
                ):
                    # åœ¨åŒä¸€å®¹å™¨å†…ä»¥ expander å½¢å¼æ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯
                    with st.expander("ğŸ”§ å·¥å…·è°ƒç”¨ä¿¡æ¯", expanded=False):
                        st.markdown(st.session_state.history[i + 1]["content"])
                    i += 2  # ä¸¤æ¡æ¶ˆæ¯ä¸€èµ·å¤„ç†ï¼Œæ‰€ä»¥åŠ 2
                else:
                    i += 1  # åªå¤„ç†æ™®é€šæ¶ˆæ¯æ—¶åŠ 1
        else:
            # assistant_tool æ¶ˆæ¯å·²åœ¨ä¸Šé¢å¤„ç†ï¼Œè·³è¿‡
            i += 1


def get_streaming_callback(text_placeholder, tool_placeholder):
    """
    åˆ›å»ºæµå¼å›è°ƒå‡½æ•°ã€‚

    è¯¥å‡½æ•°ç”¨äºå°† LLM ç”Ÿæˆçš„å“åº”å®æ—¶æ˜¾ç¤ºåœ¨ç•Œé¢ä¸Šã€‚
    åˆ†åˆ«åœ¨ä¸åŒåŒºåŸŸæ˜¾ç¤ºæ–‡æœ¬å“åº”å’Œå·¥å…·è°ƒç”¨ä¿¡æ¯ã€‚

    å‚æ•°ï¼š
        text_placeholder: ç”¨äºæ˜¾ç¤ºæ–‡æœ¬å“åº”çš„ Streamlit ç»„ä»¶
        tool_placeholder: ç”¨äºæ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯çš„ Streamlit ç»„ä»¶

    è¿”å›å€¼ï¼š
        callback_func: æµå¼å›è°ƒå‡½æ•°
        accumulated_text: å­˜å‚¨ç´¯è®¡æ–‡æœ¬å“åº”çš„åˆ—è¡¨
        accumulated_tool: å­˜å‚¨ç´¯è®¡å·¥å…·è°ƒç”¨ä¿¡æ¯çš„åˆ—è¡¨
    """
    accumulated_text = []
    accumulated_tool = []

    def callback_func(message: dict):
        nonlocal accumulated_text, accumulated_tool
        message_content = message.get("content", None)

        if isinstance(message_content, AIMessageChunk):
            content = message_content.content
            # å†…å®¹ä¸ºåˆ—è¡¨æ—¶çš„å¤„ç†ï¼ˆä¸»è¦å‡ºç°åœ¨ Claude æ¨¡å‹ç­‰ï¼‰
            if isinstance(content, list) and len(content) > 0:
                message_chunk = content[0]
                # å¤„ç†æ–‡æœ¬ç±»å‹çš„æƒ…å†µ
                if message_chunk["type"] == "text":
                    accumulated_text.append(message_chunk["text"])
                    text_placeholder.markdown("".join(accumulated_text))
                # å¤„ç†å·¥å…·ä½¿ç”¨ç±»å‹çš„æƒ…å†µ
                elif message_chunk["type"] == "tool_use":
                    if "partial_json" in message_chunk:
                        accumulated_tool.append(message_chunk["partial_json"])
                    else:
                        tool_call_chunks = message_content.tool_call_chunks
                        tool_call_chunk = tool_call_chunks[0]
                        accumulated_tool.append(
                            "\n```json\n" + str(tool_call_chunk) + "\n```\n"
                        )
                    with tool_placeholder.expander("ğŸ”§ å·¥å…·è°ƒç”¨ä¿¡æ¯", expanded=True):
                        st.markdown("".join(accumulated_tool))
            # å¤„ç† tool_calls å±æ€§çš„æƒ…å†µï¼ˆä¸»è¦å‡ºç°åœ¨ OpenAI æ¨¡å‹ç­‰ï¼‰
            elif (
                hasattr(message_content, "tool_calls")
                and message_content.tool_calls
                and len(message_content.tool_calls[0]["name"]) > 0
            ):
                tool_call_info = message_content.tool_calls[0]
                accumulated_tool.append("\n```json\n" + str(tool_call_info) + "\n```\n")
                with tool_placeholder.expander("ğŸ”§ å·¥å…·è°ƒç”¨ä¿¡æ¯", expanded=True):
                    st.markdown("".join(accumulated_tool))
            # å¤„ç†çº¯å­—ç¬¦ä¸²çš„æƒ…å†µ
            elif isinstance(content, str):
                accumulated_text.append(content)
                text_placeholder.markdown("".join(accumulated_text))
            # å¤„ç†æ— æ•ˆçš„å·¥å…·è°ƒç”¨ä¿¡æ¯
            elif (
                hasattr(message_content, "invalid_tool_calls")
                and message_content.invalid_tool_calls
            ):
                tool_call_info = message_content.invalid_tool_calls[0]
                accumulated_tool.append("\n```json\n" + str(tool_call_info) + "\n```\n")
                with tool_placeholder.expander(
                    "ğŸ”§ å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼ˆæ— æ•ˆï¼‰", expanded=True
                ):
                    st.markdown("".join(accumulated_tool))
            # å¤„ç† tool_call_chunks å±æ€§çš„æƒ…å†µ
            elif (
                hasattr(message_content, "tool_call_chunks")
                and message_content.tool_call_chunks
            ):
                tool_call_chunk = message_content.tool_call_chunks[0]
                accumulated_tool.append(
                    "\n```json\n" + str(tool_call_chunk) + "\n```\n"
                )
                with tool_placeholder.expander("ğŸ”§ å·¥å…·è°ƒç”¨ä¿¡æ¯", expanded=True):
                    st.markdown("".join(accumulated_tool))
            # å¤„ç† additional_kwargs ä¸­åŒ…å« tool_calls çš„æƒ…å†µï¼ˆæ”¯æŒå¤šç§æ¨¡å‹å…¼å®¹æ€§ï¼‰
            elif (
                hasattr(message_content, "additional_kwargs")
                and "tool_calls" in message_content.additional_kwargs
            ):
                tool_call_info = message_content.additional_kwargs["tool_calls"][0]
                accumulated_tool.append("\n```json\n" + str(tool_call_info) + "\n```\n")
                with tool_placeholder.expander("ğŸ”§ å·¥å…·è°ƒç”¨ä¿¡æ¯", expanded=True):
                    st.markdown("".join(accumulated_tool))
        # å¤„ç†å·¥å…·æ¶ˆæ¯ï¼ˆå·¥å…·å“åº”ï¼‰
        elif isinstance(message_content, ToolMessage):
            accumulated_tool.append(
                "\n```json\n" + str(message_content.content) + "\n```\n"
            )
            with tool_placeholder.expander("ğŸ”§ å·¥å…·è°ƒç”¨ä¿¡æ¯", expanded=True):
                st.markdown("".join(accumulated_tool))
        return None

    return callback_func, accumulated_text, accumulated_tool


async def process_query(query, text_placeholder, tool_placeholder, timeout_seconds=60):
    """
    å¤„ç†ç”¨æˆ·é—®é¢˜å¹¶ç”Ÿæˆå“åº”ã€‚

    è¯¥å‡½æ•°å°†ç”¨æˆ·é—®é¢˜ä¼ é€’ç»™ä»£ç†ï¼Œå¹¶ä»¥æµå¼æ–¹å¼å®æ—¶æ˜¾ç¤ºå“åº”ã€‚
    å¦‚æœåœ¨æŒ‡å®šæ—¶é—´å†…æœªå®Œæˆå“åº”ï¼Œåˆ™è¿”å›è¶…æ—¶é”™è¯¯ã€‚

    å‚æ•°ï¼š
        query: ç”¨æˆ·è¾“å…¥çš„é—®é¢˜æ–‡æœ¬
        text_placeholder: ç”¨äºæ˜¾ç¤ºæ–‡æœ¬å“åº”çš„ Streamlit ç»„ä»¶
        tool_placeholder: ç”¨äºæ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯çš„ Streamlit ç»„ä»¶
        timeout_seconds: å“åº”ç”Ÿæˆè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

    è¿”å›å€¼ï¼š
        response: ä»£ç†çš„å“åº”å¯¹è±¡
        final_text: æœ€ç»ˆæ–‡æœ¬å“åº”
        final_tool: æœ€ç»ˆå·¥å…·è°ƒç”¨ä¿¡æ¯
    """
    try:
        if st.session_state.agent:
            streaming_callback, accumulated_text_obj, accumulated_tool_obj = (
                get_streaming_callback(text_placeholder, tool_placeholder)
            )
            try:
                response = await asyncio.wait_for(
                    astream_graph(
                        st.session_state.agent,
                        {"messages": [HumanMessage(content=query)]},
                        callback=streaming_callback,
                        config=RunnableConfig(
                            recursion_limit=st.session_state.recursion_limit,
                            thread_id=st.session_state.thread_id,
                        ),
                    ),
                    timeout=timeout_seconds,
                )
            except asyncio.TimeoutError:
                error_msg = f"â±ï¸ è¯·æ±‚æ—¶é—´è¶…è¿‡ {timeout_seconds} ç§’ï¼Œè¯·ç¨åé‡è¯•ã€‚"
                return {"error": error_msg}, error_msg, ""

            final_text = "".join(accumulated_text_obj)
            final_tool = "".join(accumulated_tool_obj)
            return response, final_text, final_tool
        else:
            return (
                {"error": "ğŸš« æ™ºèƒ½ä½“å°šæœªåˆå§‹åŒ–ã€‚"},
                "ğŸš« æ™ºèƒ½ä½“å°šæœªåˆå§‹åŒ–ã€‚",
                "",
            )
    except Exception as e:
        import traceback

        error_msg = f"âŒ æŸ¥è¯¢å¤„ç†å‡ºé”™: {str(e)}\n{traceback.format_exc()}"
        return {"error": error_msg}, error_msg, ""


async def initialize_session(mcp_config=None):
    """
    åˆå§‹åŒ– MCP ä¼šè¯å’Œä»£ç†ã€‚

    å‚æ•°ï¼š
        mcp_config: MCP å·¥å…·é…ç½®ä¿¡æ¯ï¼ˆJSONï¼‰ã€‚ä¸º None æ—¶ä½¿ç”¨é»˜è®¤è®¾ç½®

    è¿”å›å€¼ï¼š
        bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
    """
    with st.spinner("ğŸ”„ æ­£åœ¨è¿æ¥ MCP æœåŠ¡å™¨â€¦â€¦"):
        # å…ˆå®‰å…¨æ¸…ç†æ—§å®¢æˆ·ç«¯
        await cleanup_mcp_client()

        if mcp_config is None:
            # ä» config.json æ–‡ä»¶åŠ è½½è®¾ç½®
            mcp_config = load_config_from_json()
        client = MultiServerMCPClient(mcp_config)
        await client.__aenter__()
        tools = client.get_tools()
        st.session_state.tool_count = len(tools)
        st.session_state.mcp_client = client

        # æ ¹æ®æ‰€é€‰æ¨¡å‹è¿›è¡Œåˆå§‹åŒ–
        selected_model = st.session_state.selected_model

        if selected_model in [
            "claude-3-7-sonnet-latest",
            "claude-3-5-sonnet-latest",
            "claude-3-5-haiku-latest",
        ]:
            model = ChatAnthropic(
                model=selected_model,
                temperature=0.1,
                max_tokens=OUTPUT_TOKEN_INFO[selected_model]["max_tokens"],
            )
        else:  # ä½¿ç”¨ OpenAI æ¨¡å‹
            model = ChatOpenAI(
                model=selected_model,
                temperature=0.1,
                max_tokens=OUTPUT_TOKEN_INFO[selected_model]["max_tokens"],
            )
        agent = create_react_agent(
            model,
            tools,
            checkpointer=MemorySaver(),
            prompt=SYSTEM_PROMPT,
        )
        st.session_state.agent = agent
        st.session_state.session_initialized = True
        return True


# --- ä¾§è¾¹æ ï¼šç³»ç»Ÿè®¾ç½®éƒ¨åˆ† ---
with st.sidebar:
    st.subheader("âš™ï¸ ç³»ç»Ÿè®¾ç½®")

    # æ¨¡å‹é€‰æ‹©åŠŸèƒ½
    # ç”Ÿæˆå¯ç”¨æ¨¡å‹åˆ—è¡¨
    available_models = []

    # æ£€æŸ¥ Anthropic API å¯†é’¥
    has_anthropic_key = os.environ.get("ANTHROPIC_API_KEY") is not None
    if has_anthropic_key:
        available_models.extend(
            [
                "claude-3-7-sonnet-latest",
                "claude-3-5-sonnet-latest",
                "claude-3-5-haiku-latest",
            ]
        )

    # æ£€æŸ¥ OpenAI API å¯†é’¥
    has_openai_key = os.environ.get("OPENAI_API_KEY") is not None
    if has_openai_key:
        available_models.extend(["gpt-4o", "gpt-4o-mini"])

    # å¦‚æœæ²¡æœ‰å¯ç”¨æ¨¡å‹åˆ™æ˜¾ç¤ºæç¤ºä¿¡æ¯
    if not available_models:
        st.warning(
            "âš ï¸ æœªè®¾ç½® API å¯†é’¥ã€‚è¯·åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ  ANTHROPIC_API_KEY æˆ– OPENAI_API_KEYã€‚"
        )
        # é»˜è®¤æ·»åŠ  Claude æ¨¡å‹ï¼ˆå³ä½¿æ²¡æœ‰å¯†é’¥ä¹Ÿæ˜¾ç¤º UIï¼‰
        available_models = ["claude-3-7-sonnet-latest"]

    # æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
    previous_model = st.session_state.selected_model
    st.session_state.selected_model = st.selectbox(
        "ğŸ¤– é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹",
        options=available_models,
        index=(
            available_models.index(st.session_state.selected_model)
            if st.session_state.selected_model in available_models
            else 0
        ),
        help="Anthropic æ¨¡å‹éœ€è®¾ç½® ANTHROPIC_API_KEYï¼ŒOpenAI æ¨¡å‹éœ€è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡ã€‚",
    )

    # å½“æ¨¡å‹æ›´æ”¹æ—¶æç¤ºéœ€è¦é‡æ–°åˆå§‹åŒ–ä¼šè¯
    if (
        previous_model != st.session_state.selected_model
        and st.session_state.session_initialized
    ):
        st.warning(
            "âš ï¸ æ¨¡å‹å·²æ›´æ”¹ï¼Œè¯·ç‚¹å‡»â€˜åº”ç”¨è®¾ç½®â€™æŒ‰é’®ä»¥åº”ç”¨æ›´æ”¹ã€‚"
        )

    # æ·»åŠ è¶…æ—¶è®¾ç½®æ»‘å—
    st.session_state.timeout_seconds = st.slider(
        "â±ï¸ å“åº”ç”Ÿæˆè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰",
        min_value=60,
        max_value=300,
        value=st.session_state.timeout_seconds,
        step=10,
        help="è®¾ç½®æ™ºèƒ½ä½“ç”Ÿæˆå“åº”çš„æœ€å¤§æ—¶é—´ã€‚å¤æ‚ä»»åŠ¡å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´ã€‚",
    )

    st.session_state.recursion_limit = st.slider(
        "â±ï¸ é€’å½’è°ƒç”¨é™åˆ¶ï¼ˆæ¬¡æ•°ï¼‰",
        min_value=10,
        max_value=200,
        value=st.session_state.recursion_limit,
        step=10,
        help="è®¾ç½®é€’å½’è°ƒç”¨æ¬¡æ•°é™åˆ¶ã€‚è®¾ç½®è¿‡é«˜å¯èƒ½å¯¼è‡´å†…å­˜ä¸è¶³ã€‚",
    )

    st.divider()  # æ·»åŠ åˆ†å‰²çº¿

    # æ·»åŠ å·¥å…·è®¾ç½®éƒ¨åˆ†
    st.subheader("ğŸ”§ å·¥å…·è®¾ç½®")

    # ç”¨ session_state ç®¡ç† expander çŠ¶æ€
    if "mcp_tools_expander" not in st.session_state:
        st.session_state.mcp_tools_expander = False

    # MCP å·¥å…·æ·»åŠ ç•Œé¢
    with st.expander("ğŸ§° æ·»åŠ  MCP å·¥å…·", expanded=st.session_state.mcp_tools_expander):
        # ä» config.json æ–‡ä»¶åŠ è½½è®¾ç½®å¹¶æ˜¾ç¤º
        loaded_config = load_config_from_json()
        default_config_text = json.dumps(loaded_config, indent=2, ensure_ascii=False)
        
        # å¦‚æœæ²¡æœ‰ pending configï¼Œåˆ™åŸºäºç°æœ‰ mcp_config_text åˆ›å»º
        if "pending_mcp_config" not in st.session_state:
            try:
                st.session_state.pending_mcp_config = loaded_config
            except Exception as e:
                st.error(f"åˆå§‹åŒ– pending config å¤±è´¥: {e}")

        # ç”¨äºå•ç‹¬æ·»åŠ å·¥å…·çš„ UI
        st.subheader("æ·»åŠ å·¥å…·")
        st.markdown(
            """
            [å¦‚ä½•è®¾ç½®ï¼Ÿ](https://teddylee777.notion.site/MCP-1d324f35d12980c8b018e12afdf545a1?pvs=4)

            âš ï¸ **é‡è¦**: JSON å¿…é¡»ç”¨å¤§æ‹¬å·ï¼ˆ`{}`ï¼‰åŒ…è£¹ã€‚"""
        )

        # æä¾›æ›´æ¸…æ™°çš„ç¤ºä¾‹
        example_json = {
            "github": {
                "command": "npx",
                "args": [
                    "-y",
                    "@smithery/cli@latest",
                    "run",
                    "@smithery-ai/github",
                    "--config",
                    '{"githubPersonalAccessToken":"your_token_here"}',
                ],
                "transport": "stdio",
            }
        }

        default_text = json.dumps(example_json, indent=2, ensure_ascii=False)

        new_tool_json = st.text_area(
            "å·¥å…· JSON",
            default_text,
            height=250,
        )

        # æ·»åŠ æŒ‰é’®
        if st.button(
            "æ·»åŠ å·¥å…·",
            type="primary",
            key="add_tool_button",
            use_container_width=True,
        ):
            try:
                # æ ¡éªŒè¾“å…¥å€¼
                if not new_tool_json.strip().startswith(
                    "{"
                ) or not new_tool_json.strip().endswith("}"):
                    st.error("JSON å¿…é¡»ä»¥å¤§æ‹¬å·ï¼ˆ{}ï¼‰å¼€å¤´å’Œç»“å°¾ã€‚")
                    st.markdown('æ­£ç¡®æ ¼å¼: `{ "å·¥å…·å": { ... } }`')
                else:
                    # è§£æ JSON
                    parsed_tool = json.loads(new_tool_json)

                    # æ£€æŸ¥æ˜¯å¦ä¸º mcpServers æ ¼å¼å¹¶å¤„ç†
                    if "mcpServers" in parsed_tool:
                        # å°† mcpServers å†…çš„å†…å®¹æå‡åˆ°æœ€å¤–å±‚
                        parsed_tool = parsed_tool["mcpServers"]
                        st.info(
                            "æ£€æµ‹åˆ° 'mcpServers' æ ¼å¼ï¼Œå·²è‡ªåŠ¨è½¬æ¢ã€‚"
                        )

                    # æ£€æŸ¥è¾“å…¥çš„å·¥å…·æ•°é‡
                    if len(parsed_tool) == 0:
                        st.error("è¯·è‡³å°‘è¾“å…¥ä¸€ä¸ªå·¥å…·ã€‚")
                    else:
                        # å¤„ç†æ‰€æœ‰å·¥å…·
                        success_tools = []
                        for tool_name, tool_config in parsed_tool.items():
                            # æ£€æŸ¥ URL å­—æ®µå¹¶è®¾ç½® transport
                            if "url" in tool_config:
                                # å¦‚æœæœ‰ URLï¼Œåˆ™å°† transport è®¾ç½®ä¸º "sse"
                                tool_config["transport"] = "sse"
                                st.info(
                                    f"æ£€æµ‹åˆ° '{tool_name}' å·¥å…·æœ‰ URLï¼Œå·²å°† transport è®¾ç½®ä¸º 'sse'ã€‚"
                                )
                            elif "transport" not in tool_config:
                                # å¦‚æœæ²¡æœ‰ URL ä¸”æ²¡æœ‰ transportï¼Œåˆ™é»˜è®¤è®¾ç½®ä¸º "stdio"
                                tool_config["transport"] = "stdio"

                            # æ£€æŸ¥å¿…å¡«å­—æ®µ
                            if (
                                "command" not in tool_config
                                and "url" not in tool_config
                            ):
                                st.error(
                                    f"'{tool_name}' å·¥å…·è®¾ç½®éœ€è¦ 'command' æˆ– 'url' å­—æ®µã€‚"
                                )
                            elif "command" in tool_config and "args" not in tool_config:
                                st.error(
                                    f"'{tool_name}' å·¥å…·è®¾ç½®éœ€è¦ 'args' å­—æ®µã€‚"
                                )
                            elif "command" in tool_config and not isinstance(
                                tool_config["args"], list
                            ):
                                st.error(
                                    f"'{tool_name}' å·¥å…·çš„ 'args' å­—æ®µå¿…é¡»ä¸ºæ•°ç»„ï¼ˆ[]ï¼‰æ ¼å¼ã€‚"
                                )
                            else:
                                # å‘ pending_mcp_config æ·»åŠ å·¥å…·
                                st.session_state.pending_mcp_config[tool_name] = (
                                    tool_config
                                )
                                success_tools.append(tool_name)

                        # æˆåŠŸæ¶ˆæ¯
                        if success_tools:
                            if len(success_tools) == 1:
                                st.success(
                                    f"å·²æ·»åŠ  {success_tools[0]} å·¥å…·ã€‚è¯·ç‚¹å‡» 'åº”ç”¨è®¾ç½®' æŒ‰é’®ä»¥ç”Ÿæ•ˆã€‚"
                                )
                            else:
                                tool_names = ", ".join(success_tools)
                                st.success(
                                    f"å…±æ·»åŠ  {len(success_tools)} ä¸ªå·¥å…·ï¼ˆ{tool_names}ï¼‰ã€‚è¯·ç‚¹å‡» 'åº”ç”¨è®¾ç½®' æŒ‰é’®ä»¥ç”Ÿæ•ˆã€‚"
                                )
                            # æ·»åŠ åæ”¶èµ· expander
                            st.session_state.mcp_tools_expander = False
                            st.rerun()
            except json.JSONDecodeError as e:
                st.error(f"JSON è§£æé”™è¯¯: {e}")
                st.markdown(
                    f"""
                **ä¿®æ­£æ–¹æ³•**ï¼š
                1. è¯·ç¡®ä¿ JSON æ ¼å¼æ­£ç¡®ã€‚
                2. æ‰€æœ‰é”®éƒ½è¦ç”¨åŒå¼•å·ï¼ˆ"ï¼‰åŒ…è£¹ã€‚
                3. å­—ç¬¦ä¸²å€¼ä¹Ÿè¦ç”¨åŒå¼•å·ï¼ˆ"ï¼‰åŒ…è£¹ã€‚
                4. å­—ç¬¦ä¸²ä¸­å¦‚éœ€ä½¿ç”¨åŒå¼•å·è¯·ä½¿ç”¨è½¬ä¹‰ï¼ˆ\\"ï¼‰ã€‚
                """
                )
            except Exception as e:
                st.error(f"å‘ç”Ÿé”™è¯¯: {e}")

    # æ˜¾ç¤ºå·²æ³¨å†Œå·¥å…·åˆ—è¡¨å¹¶æ·»åŠ åˆ é™¤æŒ‰é’®
    with st.expander("ğŸ“‹ å·²æ³¨å†Œå·¥å…·åˆ—è¡¨", expanded=True):
        try:
            pending_config = st.session_state.pending_mcp_config
        except Exception as e:
            st.error("æ— æ•ˆçš„ MCP å·¥å…·è®¾ç½®ã€‚")
        else:
            # éå† pending config çš„é”®ï¼ˆå·¥å…·åï¼‰å¹¶æ˜¾ç¤º
            for tool_name in list(pending_config.keys()):
                col1, col2 = st.columns([8, 2])
                col1.markdown(f"- **{tool_name}**")
                if col2.button("åˆ é™¤", key=f"delete_{tool_name}"):
                    # ä» pending config åˆ é™¤è¯¥å·¥å…·ï¼ˆä¸ä¼šç«‹å³ç”Ÿæ•ˆï¼‰
                    del st.session_state.pending_mcp_config[tool_name]
                    st.success(
                        f"å·²åˆ é™¤ {tool_name} å·¥å…·ã€‚è¯·ç‚¹å‡» 'åº”ç”¨è®¾ç½®' æŒ‰é’®ä»¥ç”Ÿæ•ˆã€‚"
                    )

    st.divider()  # æ·»åŠ åˆ†å‰²çº¿

# --- ä¾§è¾¹æ ï¼šç³»ç»Ÿä¿¡æ¯ä¸æ“ä½œæŒ‰é’®éƒ¨åˆ† ---
with st.sidebar:
    st.subheader("ğŸ“Š ç³»ç»Ÿä¿¡æ¯")
    st.write(f"ğŸ› ï¸ MCP å·¥å…·æ•°é‡: {st.session_state.get('tool_count', 'åˆå§‹åŒ–ä¸­...')}")
    selected_model_name = st.session_state.selected_model
    st.write(f"ğŸ§  å½“å‰æ¨¡å‹: {selected_model_name}")

    # å°†â€œåº”ç”¨è®¾ç½®â€æŒ‰é’®ç§»åˆ°è¿™é‡Œ
    if st.button(
        "åº”ç”¨è®¾ç½®",
        key="apply_button",
        type="primary",
        use_container_width=True,
    ):
        # æ˜¾ç¤ºåº”ç”¨ä¸­æ¶ˆæ¯
        apply_status = st.empty()
        with apply_status.container():
            st.warning("ğŸ”„ æ­£åœ¨åº”ç”¨æ›´æ”¹ï¼Œè¯·ç¨å€™â€¦â€¦")
            progress_bar = st.progress(0)

            # ä¿å­˜è®¾ç½®
            st.session_state.mcp_config_text = json.dumps(
                st.session_state.pending_mcp_config, indent=2, ensure_ascii=False
            )

            # ä¿å­˜è®¾ç½®åˆ° config.json æ–‡ä»¶
            save_result = save_config_to_json(st.session_state.pending_mcp_config)
            if not save_result:
                st.error("âŒ è®¾ç½®æ–‡ä»¶ä¿å­˜å¤±è´¥ã€‚")
            
            progress_bar.progress(15)

            # å‡†å¤‡ä¼šè¯åˆå§‹åŒ–
            st.session_state.session_initialized = False
            st.session_state.agent = None

            # æ›´æ–°è¿›åº¦çŠ¶æ€
            progress_bar.progress(30)

            # æ‰§è¡Œåˆå§‹åŒ–
            success = st.session_state.event_loop.run_until_complete(
                initialize_session(st.session_state.pending_mcp_config)
            )

            # æ›´æ–°è¿›åº¦çŠ¶æ€
            progress_bar.progress(100)

            if success:
                st.success("âœ… æ–°è®¾ç½®å·²åº”ç”¨ã€‚")
                # æ”¶èµ·å·¥å…·æ·»åŠ  expander
                if "mcp_tools_expander" in st.session_state:
                    st.session_state.mcp_tools_expander = False
            else:
                st.error("âŒ è®¾ç½®åº”ç”¨å¤±è´¥ã€‚")

        # é¡µé¢åˆ·æ–°
        st.rerun()

    st.divider()  # æ·»åŠ åˆ†å‰²çº¿

    # æ“ä½œæŒ‰é’®éƒ¨åˆ†
    st.subheader("ğŸ”„ æ“ä½œ")

    # å¯¹è¯åˆå§‹åŒ–æŒ‰é’®
    if st.button("é‡ç½®å¯¹è¯", use_container_width=True, type="primary"):
        # åˆå§‹åŒ– thread_id
        st.session_state.thread_id = random_uuid()

        # åˆå§‹åŒ–å¯¹è¯å†å²
        st.session_state.history = []

        # æç¤ºæ¶ˆæ¯
        st.success("âœ… å¯¹è¯å·²é‡ç½®ã€‚")

        # é¡µé¢åˆ·æ–°
        st.rerun()

    # ä»…åœ¨å¯ç”¨ç™»å½•åŠŸèƒ½æ—¶æ˜¾ç¤ºç™»å‡ºæŒ‰é’®
    if use_login and st.session_state.authenticated:
        st.divider()  # æ·»åŠ åˆ†å‰²çº¿
        if st.button("ç™»å‡º", use_container_width=True, type="secondary"):
            st.session_state.authenticated = False
            st.success("âœ… å·²ç™»å‡ºã€‚")
            st.rerun()

# --- é»˜è®¤ä¼šè¯åˆå§‹åŒ–ï¼ˆæœªåˆå§‹åŒ–æ—¶ï¼‰ ---
if not st.session_state.session_initialized:
    st.info(
        "MCP æœåŠ¡å™¨å’Œä»£ç†å°šæœªåˆå§‹åŒ–ã€‚è¯·ç‚¹å‡»å·¦ä¾§è¾¹æ çš„ 'åº”ç”¨è®¾ç½®' æŒ‰é’®è¿›è¡Œåˆå§‹åŒ–ã€‚"
    )


# --- è¾“å‡ºå¯¹è¯è®°å½• ---
print_message()

# --- ç”¨æˆ·è¾“å…¥ä¸å¤„ç† ---
user_query = st.chat_input("ğŸ’¬ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜")
if user_query:
    if st.session_state.session_initialized:
        st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").markdown(user_query)
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            tool_placeholder = st.empty()
            text_placeholder = st.empty()
            resp, final_text, final_tool = (
                st.session_state.event_loop.run_until_complete(
                    process_query(
                        user_query,
                        text_placeholder,
                        tool_placeholder,
                        st.session_state.timeout_seconds,
                    )
                )
            )
        if "error" in resp:
            st.error(resp["error"])
        else:
            st.session_state.history.append({"role": "user", "content": user_query})
            st.session_state.history.append(
                {"role": "assistant", "content": final_text}
            )
            if final_tool.strip():
                st.session_state.history.append(
                    {"role": "assistant_tool", "content": final_tool}
                )
            st.rerun()
    else:
        st.warning(
            "âš ï¸ MCP æœåŠ¡å™¨å’Œæ™ºèƒ½ä½“å°šæœªåˆå§‹åŒ–ã€‚è¯·ç‚¹å‡»å·¦ä¾§è¾¹æ çš„ 'åº”ç”¨è®¾ç½®' æŒ‰é’®è¿›è¡Œåˆå§‹åŒ–ã€‚"
        )
